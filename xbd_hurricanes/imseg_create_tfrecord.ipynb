{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imseg_create_tfrecord.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "haMrhUMoE8S_",
        "outputId": "17440c48-fed1-4fe0-fcea-9290bf5feda3"
      },
      "source": [
        "# Written by Dr Daniel Buscombe, Marda Science LLC\n",
        "#\n",
        "# MIT License\n",
        "#\n",
        "# Copyright (c) 2020, Marda Science LLC\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in all\n",
        "# copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "# SOFTWARE.\n",
        "\n",
        "import os\n",
        "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "\n",
        "##calcs\n",
        "import tensorflow as tf #numerical operations on gpu\n",
        "import numpy as np\n",
        "from imageio import imwrite\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED=42\n",
        "np.random.seed(SEED)\n",
        "AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "\n",
        "TARGET_SIZE = 1024\n",
        "ims_per_shard = 20\n",
        "\n",
        "\n",
        "#-----------------------------------\n",
        "def get_seg_dataset_for_tfrecords(imdir, lab_path, shared_size):\n",
        "    \"\"\"\n",
        "    \"get_seg_dataset_for_tfrecords\"\n",
        "    This function reads an image and label and decodes both jpegs\n",
        "    into bytestring arrays.\n",
        "    This is the version for data, which differs in use of both\n",
        "    resize_and_crop_seg_image and resize_and_crop_seg_image\n",
        "    for image pre-processing\n",
        "    INPUTS:\n",
        "        * image [tensor array]\n",
        "        * label [tensor array]\n",
        "    OPTIONAL INPUTS: None\n",
        "    GLOBAL INPUTS: TARGET_SIZE\n",
        "    OUTPUTS:\n",
        "        * image [tensor array]\n",
        "        * label [tensor array]\n",
        "    \"\"\"\n",
        "    dataset = tf.data.Dataset.list_files(imdir+os.sep+'*.png', seed=10000) # This also shuffles the images\n",
        "    dataset = dataset.map(read_seg_image_and_label)\n",
        "    dataset = dataset.map(resize_and_crop_seg_image, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.map(recompress_seg_image, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.batch(shared_size)\n",
        "    return dataset\n",
        "\n",
        "#-----------------------------------\n",
        "def read_seg_image_and_label(img_path):\n",
        "    \"\"\"\n",
        "    \"read_seg_image_and_label(img_path)\"\n",
        "    This function reads an image and label and decodes both jpegs\n",
        "    into bytestring arrays.\n",
        "    This works by parsing out the label image filename from its image pair\n",
        "    Thre are different rules for non-augmented versus augmented imagery\n",
        "    INPUTS:\n",
        "        * img_path [tensor string]\n",
        "    OPTIONAL INPUTS: None\n",
        "    GLOBAL INPUTS: None\n",
        "    OUTPUTS:\n",
        "        * image [bytestring]\n",
        "        * label [bytestring]\n",
        "    \"\"\"\n",
        "    bits = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_png(bits)\n",
        "\n",
        "    # have to use this tf.strings.regex_replace utility because img_path is a Tensor object\n",
        "    lab_path = tf.strings.regex_replace(img_path, \"images\", \"labels2D\")\n",
        "\n",
        "    lab_path = tf.cast(lab_path, tf.string)\n",
        "    #if not_contains(lab_path, \"pre\"): #tf.constant('post') in lab_name: # #tf.strings.regex_full_match(lab_path, tf.constant(\"post\")): #\n",
        "    lab_path = tf.strings.regex_replace(lab_path, \"_post_disaster.png\", \"_post_disaster_post_labelimage.png\")\n",
        "    #else:\n",
        "    lab_path = tf.strings.regex_replace(lab_path, \"_pre_disaster.png\", \"_pre_disaster_pre_labelimage.png\")\n",
        "\n",
        "    lab_path = tf.cast(lab_path, tf.string)\n",
        "\n",
        "    bits = tf.io.read_file(lab_path)\n",
        "    label = tf.image.decode_png(bits)\n",
        "\n",
        "    cond = tf.equal(label, tf.ones(tf.shape(label),dtype=tf.uint8)*7)\n",
        "    label = tf.where(cond,  tf.ones(tf.shape(label),dtype=tf.uint8)*6, label)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "#-----------------------------------\n",
        "def resize_and_crop_seg_image(image, label):\n",
        "    \"\"\"\n",
        "    \"resize_and_crop_seg_image\"\n",
        "    This function crops to square and resizes an image and label\n",
        "    INPUTS:\n",
        "        * image [tensor array]\n",
        "        * label [tensor array]\n",
        "    OPTIONAL INPUTS: None\n",
        "    GLOBAL INPUTS: TARGET_SIZE\n",
        "    OUTPUTS:\n",
        "        * image [tensor array]\n",
        "        * label [tensor array]\n",
        "    \"\"\"\n",
        "    w = tf.shape(image)[0]\n",
        "    h = tf.shape(image)[1]\n",
        "    tw = TARGET_SIZE\n",
        "    th = TARGET_SIZE\n",
        "    resize_crit = (w * th) / (h * tw)\n",
        "    image = tf.cond(resize_crit < 1,\n",
        "                  lambda: tf.image.resize(image, [w*tw/w, h*tw/w]), # if true\n",
        "                  lambda: tf.image.resize(image, [w*th/h, h*th/h])  # if false\n",
        "                 )\n",
        "    nw = tf.shape(image)[0]\n",
        "    nh = tf.shape(image)[1]\n",
        "    image = tf.image.crop_to_bounding_box(image, (nw - tw) // 2, (nh - th) // 2, tw, th)\n",
        "\n",
        "    label = tf.cond(resize_crit < 1,\n",
        "                  lambda: tf.image.resize(label, [w*tw/w, h*tw/w]), # if true\n",
        "                  lambda: tf.image.resize(label, [w*th/h, h*th/h])  # if false\n",
        "                 )\n",
        "    label = tf.image.crop_to_bounding_box(label, (nw - tw) // 2, (nh - th) // 2, tw, th)\n",
        "\n",
        "    label = tf.cast(label, tf.uint8)\n",
        "    cond = tf.equal(label, tf.ones(tf.shape(label),dtype=tf.uint8)*7)\n",
        "    label = tf.where(cond,  tf.ones(tf.shape(label),dtype=tf.uint8)*6, label)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "#-----------------------------------\n",
        "def recompress_seg_image(image, label):\n",
        "    \"\"\"\n",
        "    \"recompress_seg_image\"\n",
        "    This function takes an image and label encoded as a byte string\n",
        "    and recodes as an 8-bit jpeg\n",
        "    INPUTS:\n",
        "        * image [tensor array]\n",
        "        * label [tensor array]\n",
        "    OPTIONAL INPUTS: None\n",
        "    GLOBAL INPUTS: None\n",
        "    OUTPUTS:\n",
        "        * image [tensor array]\n",
        "        * label [tensor array]\n",
        "    \"\"\"\n",
        "    image = tf.cast(image, tf.uint8)\n",
        "    image = tf.image.encode_png(image)#, optimize_size=True, chroma_downsampling=False)\n",
        "\n",
        "    label = tf.cast(label, tf.uint8)\n",
        "\n",
        "    cond = tf.equal(label, tf.ones(tf.shape(label),dtype=tf.uint8)*7)\n",
        "    label = tf.where(cond,  tf.ones(tf.shape(label),dtype=tf.uint8)*6, label)\n",
        "\n",
        "    label = tf.image.encode_png(label)#, optimize_size=True, chroma_downsampling=False)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "#-----------------------------------\n",
        "def write_seg_records(dataset, tfrecord_dir, storm):\n",
        "    \"\"\"\n",
        "    \"write_seg_records(dataset, tfrecord_dir)\"\n",
        "    This function writes a tf.data.Dataset object to TFRecord shards\n",
        "    The version for data preprends \"\" to the filenames, but otherwise is identical\n",
        "    to write_seg_records\n",
        "    INPUTS:\n",
        "        * dataset [tf.data.Dataset]\n",
        "        * tfrecord_dir [string] : path to directory where files will be written\n",
        "    OPTIONAL INPUTS: None\n",
        "    GLOBAL INPUTS: None\n",
        "    OUTPUTS: None (files written to disk)\n",
        "    \"\"\"\n",
        "    for shard, (image, label) in enumerate(dataset):\n",
        "      shard_size = image.numpy().shape[0]\n",
        "      filename = tfrecord_dir+os.sep+\"hurricane-\"+storm + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n",
        "\n",
        "      with tf.io.TFRecordWriter(filename) as out_file:\n",
        "        for i in range(shard_size):\n",
        "          example = to_seg_tfrecord(image.numpy()[i],label.numpy()[i])\n",
        "          out_file.write(example.SerializeToString())\n",
        "        print(\"Wrote file {} containing {} records\".format(filename, shard_size))\n",
        "\n",
        "#-----------------------------------\n",
        "def _bytestring_feature(list_of_bytestrings):\n",
        "    \"\"\"\n",
        "    \"_bytestring_feature\"\n",
        "    cast inputs into tf dataset 'feature' classes\n",
        "    INPUTS:\n",
        "        * list_of_bytestrings\n",
        "    OPTIONAL INPUTS:\n",
        "    GLOBAL INPUTS:\n",
        "    OUTPUTS: tf.train.Feature example\n",
        "    \"\"\"\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
        "\n",
        "#-----------------------------------\n",
        "def to_seg_tfrecord(img_bytes, label_bytes):\n",
        "    \"\"\"\n",
        "    \"to_seg_tfrecord\"\n",
        "    This function creates a TFRecord example from an image byte string and a label feature\n",
        "    INPUTS:\n",
        "        * img_bytes\n",
        "        * label_bytes\n",
        "    OPTIONAL INPUTS: None\n",
        "    GLOBAL INPUTS: None\n",
        "    OUTPUTS: tf.train.Feature example\n",
        "    \"\"\"\n",
        "    feature = {\n",
        "      \"image\": _bytestring_feature([img_bytes]), # one image in the list\n",
        "      \"label\": _bytestring_feature([label_bytes]), # one label image in the list\n",
        "              }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "#-----------------------------------\n",
        "def seg_file2tensor(f):\n",
        "    \"\"\"\n",
        "    \"seg_file2tensor(f)\"\n",
        "    This function reads a jpeg image from file into a cropped and resized tensor,\n",
        "    for use in prediction with a trained segmentation model\n",
        "    INPUTS:\n",
        "        * f [string] file name of jpeg\n",
        "    OPTIONAL INPUTS: None\n",
        "    OUTPUTS:\n",
        "        * image [tensor array]: unstandardized image\n",
        "    GLOBAL INPUTS: TARGET_SIZE\n",
        "    \"\"\"\n",
        "    bits = tf.io.read_file(f)\n",
        "    image = tf.image.decode_png(bits)\n",
        "\n",
        "    w = tf.shape(image)[0]\n",
        "    h = tf.shape(image)[1]\n",
        "    tw = TARGET_SIZE\n",
        "    th = TARGET_SIZE\n",
        "    resize_crit = (w * th) / (h * tw)\n",
        "    image = tf.cond(resize_crit < 1,\n",
        "                  lambda: tf.image.resize(image, [w*tw/w, h*tw/w]), # if true\n",
        "                  lambda: tf.image.resize(image, [w*th/h, h*th/h])  # if false\n",
        "                 )\n",
        "\n",
        "    nw = tf.shape(image)[0]\n",
        "    nh = tf.shape(image)[1]\n",
        "    image = tf.image.crop_to_bounding_box(image, (nw - tw) // 2, (nh - th) // 2, tw, th)\n",
        "    # image = tf.cast(image, tf.uint8) #/ 255.0\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "###############################################################\n",
        "## VARIABLES\n",
        "###############################################################\n",
        "damage_dict = {\n",
        "    \"no-damage\": (0, 255, 0),\n",
        "    \"minor-damage\": (0, 0, 255),\n",
        "    \"major-damage\": (255, 69, 0),\n",
        "    \"destroyed\": (255, 0, 0),\n",
        "    \"un-classified\": (255, 255, 255)\n",
        "}\n",
        "cols = [damage_dict[k] for k in damage_dict]\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "for storm in ['matthew', 'michael', 'florence', 'harvey']:\n",
        "\n",
        "    imdir = '/media/marda/TWOTB1/xBD/hurricanes/images/'+storm\n",
        "\n",
        "    lab_path =  '/media/marda/TWOTB1/xBD/hurricanes/labels2D/'+storm\n",
        "\n",
        "    tfrecord_dir = '/media/marda/TWOTB1/xBD/hurricanes/tfrecords/'+storm+'/imseg'\n",
        "\n",
        "\n",
        "    ###############################################################\n",
        "    ## EXECUTION\n",
        "    ###############################################################\n",
        "\n",
        "    nb_images=len(tf.io.gfile.glob(imdir+os.sep+'*.png'))\n",
        "\n",
        "    SHARDS = int(nb_images / ims_per_shard) + (1 if nb_images % ims_per_shard != 0 else 0)\n",
        "\n",
        "    shared_size = int(np.ceil(1.0 * nb_images / SHARDS))\n",
        "\n",
        "    dataset = get_seg_dataset_for_tfrecords(imdir, lab_path, shared_size)\n",
        "\n",
        "    ##view a batch\n",
        "    for imgs,lbls in dataset.take(1):\n",
        "      imgs = imgs[:BATCH_SIZE]\n",
        "      lbls = lbls[:BATCH_SIZE]\n",
        "      for count,(im,lab) in enumerate(zip(imgs,lbls)):\n",
        "         lab = tf.image.decode_png(lab, channels=1)\n",
        "         plt.subplot(int(BATCH_SIZE/2),int(BATCH_SIZE/2),count+1)\n",
        "         plt.imshow(tf.image.decode_png(im, channels=3))\n",
        "         plt.imshow(lab, alpha=0.5, cmap='bwr')\n",
        "         plt.axis('off')\n",
        "         print(np.unique(lab.numpy().flatten()))\n",
        "    plt.show()\n",
        "\n",
        "    write_seg_records(dataset, tfrecord_dir, storm)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version:  2.7.0\n",
            "Eager mode:  True\n",
            "GPU name:  []\n",
            "Num GPUs Available:  0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-44845517ebc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mSHARDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_images\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mims_per_shard\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnb_images\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mims_per_shard\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mshared_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnb_images\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mSHARDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_seg_dataset_for_tfrecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    }
  ]
}